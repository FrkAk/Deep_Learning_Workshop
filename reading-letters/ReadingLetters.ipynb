{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/FrkAk/Deep_Learning_Workshop/blob/master/reading-letters/ReadingLetters.ipynb\" target=\"_parent\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How to create a basic brain for recognition of handwritten letters\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data\n",
    "\n",
    "We will use two different dataset to teach our machine to how read letters. First one is famous datasets MNIST for digit and another one is Kaggle AZ dataset from Kaggle.\n",
    "\n",
    "MNIST dataset is already available in keras library or alternatively in tensorflow dataset library so do not worry about it. However, for AZ dataset we will manually download it from kaggle. (â‰ˆ700MB)\n",
    "\n",
    "### Load the MNIST dataset:\n",
    "Make sure that tensorflow_datasets is already installed. If not simply type terminal: pip install tensorflow_datasets\n",
    "\n",
    "### Load the AZ dataset:\n",
    "\n",
    "Use the following link to download to dataset on to your machine and unzip to following directory ~/AZ_dataset/.\n",
    "https://www.kaggle.com/datasets/sachinpatel21/az-handwritten-alphabets-in-csv-format\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "(mnist_train, mnist_test), mnist_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "az_dataset_directory = \"AZ_dataset/A_ZHandwrittenData.csv\"\n",
    "az_data = pd.read_csv(az_dataset_directory,header= None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "AZ dataset contains labels and images at one row. First row is Label and rest is image itself."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "az_label = az_data.values[:,0]\n",
    "az_image = az_data.values[:,1:]\n",
    "az_image = np.reshape(az_image,(az_image.shape[0],28,28,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before go through create our model these two dataset needs to be merged. Since MNIST dataset is already done with library call, we try to adapt AZ dataset to MNIST.\n",
    "\n",
    "To split our training and validation sets, we will use sklearn library.\n",
    "\n",
    "But first we need to find size of test and train set to merge without headache."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_ratio = float(mnist_info.splits['test'].shard_lengths[0] / mnist_info.splits['train'].shard_lengths[0])\n",
    "az_train_im, az_test_im, az_train_label, az_test_label = train_test_split(az_image,az_label,test_size=test_ratio)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images_mnist,train_labels_mnist),(test_images_mnist,test_labels_mnist) = mnist.load_data()\n",
    "# images are reshaped to be used by the flow method of a keras ImageGenerator\n",
    "train_images_mnist = np.reshape(train_images_mnist,(train_images_mnist.shape[0],28,28,1))\n",
    "test_images_mnist = np.reshape(test_images_mnist,(test_images_mnist.shape[0],28,28,1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_labels_mnist = train_labels_mnist + max(az_label)+1\n",
    "test_labels_mnist = test_labels_mnist + max(az_label)+1\n",
    "# #shift mnist labels\n",
    "# mnist_train.element_spec[1] = mnist_train.element_spec[1] + max(az_label)+1\n",
    "# mnist_test.element_spec[1] = mnist_test.element_spec[1] + max(az_label)+1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# concatenate datasets\n",
    "train_images = np.concatenate((az_train_im,train_images_mnist),axis=0)\n",
    "train_labels = np.concatenate((az_train_label,train_labels_mnist))\n",
    "test_images = np.concatenate((az_test_im,test_images_mnist),axis=0)\n",
    "test_labels = np.concatenate((az_test_label,test_labels_mnist))\n",
    "\n",
    "total_class = len(np.unique(train_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(8,(3,3),activation='relu'),\n",
    "    #tf.keras.layers.Dropout(0,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation='relu'),\n",
    "    tf.keras.layers.Dense(total_class, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 8)           1160      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 72)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               37376     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 36)                18468     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,948\n",
      "Trainable params: 61,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=15,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=False,\n",
    "      fill_mode='nearest'\n",
    ")\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "      rescale=1./255\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Flow training images in batches using generator\n",
    "train_generator = train_datagen.flow(train_images, train_labels, batch_size=50, shuffle=True)\n",
    "validation_generator = test_datagen.flow(test_images, test_labels, batch_size=50, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights every 10 epochs\n",
    "save_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='saved_model/',\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq= 5)\n",
    "early_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs= 100,\n",
    "    batch_size = 50,\n",
    "    verbose=2,\n",
    "    callbacks=[save_callback,early_callback]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}