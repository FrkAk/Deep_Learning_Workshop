{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/FrkAk/Deep_Learning_Workshop/blob/master/reading-letters/ReadingLetters.ipynb\" target=\"_parent\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How to create a basic brain for recognition of handwritten letters\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data\n",
    "\n",
    "We will use two different dataset to teach our machine to how read letters. First one is famous datasets MNIST for digit and another one is Kaggle AZ dataset from Kaggle.\n",
    "\n",
    "MNIST dataset is already available in keras library or alternatively in tensorflow dataset library so do not worry about it. However, for AZ dataset we will manually download it from kaggle. (â‰ˆ700MB)\n",
    "\n",
    "### Load the MNIST dataset:\n",
    "Make sure that tensorflow_datasets is already installed. If not simply type terminal: pip install tensorflow_datasets\n",
    "\n",
    "### Load the AZ dataset:\n",
    "\n",
    "Use the following link to download to dataset on to your machine and unzip to following directory ~/AZ_dataset/.\n",
    "https://www.kaggle.com/datasets/sachinpatel21/az-handwritten-alphabets-in-csv-format\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(mnist_train, mnist_test), mnist_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "az_dataset_directory = \"AZ_dataset/A_ZHandwrittenData.csv\"\n",
    "az_data = pd.read_csv(az_dataset_directory,header= None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "AZ dataset contains labels and images at one row. First row is Label and rest is image itself."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "az_label = az_data.values[:,0]\n",
    "az_image = az_data.values[:,1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before go through create our model these two dataset needs to be merged. Since MNIST dataset is already done with library call, we try to adapt AZ dataset to MNIST.\n",
    "\n",
    "To split our training and validation sets, we will use sklearn library.\n",
    "\n",
    "But first we need to find size of test and train set to merge without headache."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'TensorSpec' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [30]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m az_train_im, az_test_im, az_train_label, az_test_label \u001B[38;5;241m=\u001B[39m train_test_split(az_image,az_label,test_size\u001B[38;5;241m=\u001B[39mtest_ratio)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#shift mnist labels\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m mnist_train\u001B[38;5;241m.\u001B[39melement_spec[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mmnist_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43melement_spec\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mmax\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43maz_label\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m      8\u001B[0m mnist_test\u001B[38;5;241m.\u001B[39melement_spec[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m mnist_test\u001B[38;5;241m.\u001B[39melement_spec[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mmax\u001B[39m(az_label)\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for +: 'TensorSpec' and 'int'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_ratio = float(mnist_info.splits['test'].shard_lengths[0] / mnist_info.splits['train'].shard_lengths[0])\n",
    "az_train_im, az_test_im, az_train_label, az_test_label = train_test_split(az_image,az_label,test_size=test_ratio)\n",
    "\n",
    "#shift mnist labels\n",
    "mnist_train.element_spec[1] = mnist_train.element_spec[1] + max(az_label)+1\n",
    "mnist_test.element_spec[1] = mnist_test.element_spec[1] + max(az_label)+1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}